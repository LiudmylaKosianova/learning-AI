{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deac2c5d-da6c-415c-a53f-61a60b3229c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0b557b-68eb-4870-aba5-38064776a81a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import and prepare data\n",
    "\n",
    "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
    "concrete_data.isnull().sum()\n",
    "\n",
    "concrete_data_columns = concrete_data.columns\n",
    "\n",
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
    "target = concrete_data['Strength'] # Strength column\n",
    "\n",
    "n_cols = predictors.shape[1] # number of predictors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0388438c-6423-44f9-9d6d-db17c66bec9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:508: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3837: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6127bbb8-1c80-41e9-ad91-f55f61ab36d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Split date into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4fe2658-faf4-4a18-8cdf-a888e1a98558",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:977: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:964: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 504 samples, validate on 217 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 18:00:43.382031: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "2024-01-04 18:00:43.387718: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2394310000 Hz\n",
      "2024-01-04 18:00:43.388565: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557c0fc47640 executing computations on platform Host. Devices:\n",
      "2024-01-04 18:00:43.388624: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2024-01-04 18:00:43.476663: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 3295.7962 - val_loss: 3173.8145\n",
      "Epoch 2/50\n",
      " - 0s - loss: 2238.8743 - val_loss: 2140.4104\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1616.6802 - val_loss: 1484.2238\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1201.5069 - val_loss: 1047.0781\n",
      "Epoch 5/50\n",
      " - 0s - loss: 921.8115 - val_loss: 787.9350\n",
      "Epoch 6/50\n",
      " - 0s - loss: 728.9453 - val_loss: 615.7834\n",
      "Epoch 7/50\n",
      " - 0s - loss: 588.4369 - val_loss: 490.1353\n",
      "Epoch 8/50\n",
      " - 0s - loss: 482.9893 - val_loss: 416.2126\n",
      "Epoch 9/50\n",
      " - 0s - loss: 400.0922 - val_loss: 331.5560\n",
      "Epoch 10/50\n",
      " - 0s - loss: 345.0364 - val_loss: 288.1270\n",
      "Epoch 11/50\n",
      " - 0s - loss: 309.0348 - val_loss: 264.7299\n",
      "Epoch 12/50\n",
      " - 0s - loss: 271.7775 - val_loss: 215.9556\n",
      "Epoch 13/50\n",
      " - 0s - loss: 250.2239 - val_loss: 200.5029\n",
      "Epoch 14/50\n",
      " - 0s - loss: 213.0867 - val_loss: 200.7996\n",
      "Epoch 15/50\n",
      " - 0s - loss: 196.9643 - val_loss: 167.0553\n",
      "Epoch 16/50\n",
      " - 0s - loss: 185.7536 - val_loss: 159.6102\n",
      "Epoch 17/50\n",
      " - 0s - loss: 174.3690 - val_loss: 157.3954\n",
      "Epoch 18/50\n",
      " - 0s - loss: 165.0884 - val_loss: 147.9269\n",
      "Epoch 19/50\n",
      " - 0s - loss: 158.4844 - val_loss: 144.2635\n",
      "Epoch 20/50\n",
      " - 0s - loss: 151.3407 - val_loss: 138.6333\n",
      "Epoch 21/50\n",
      " - 0s - loss: 147.7164 - val_loss: 137.2727\n",
      "Epoch 22/50\n",
      " - 0s - loss: 142.4693 - val_loss: 132.3899\n",
      "Epoch 23/50\n",
      " - 0s - loss: 138.4489 - val_loss: 130.9937\n",
      "Epoch 24/50\n",
      " - 0s - loss: 134.9514 - val_loss: 123.2174\n",
      "Epoch 25/50\n",
      " - 0s - loss: 130.5740 - val_loss: 117.4631\n",
      "Epoch 26/50\n",
      " - 0s - loss: 130.1568 - val_loss: 115.9066\n",
      "Epoch 27/50\n",
      " - 0s - loss: 126.9665 - val_loss: 122.4931\n",
      "Epoch 28/50\n",
      " - 0s - loss: 118.9911 - val_loss: 121.3804\n",
      "Epoch 29/50\n",
      " - 0s - loss: 120.5854 - val_loss: 110.0900\n",
      "Epoch 30/50\n",
      " - 0s - loss: 115.9660 - val_loss: 110.4518\n",
      "Epoch 31/50\n",
      " - 0s - loss: 111.8344 - val_loss: 105.8383\n",
      "Epoch 32/50\n",
      " - 0s - loss: 111.8744 - val_loss: 106.5919\n",
      "Epoch 33/50\n",
      " - 0s - loss: 110.4437 - val_loss: 109.2653\n",
      "Epoch 34/50\n",
      " - 0s - loss: 110.5702 - val_loss: 102.3679\n",
      "Epoch 35/50\n",
      " - 0s - loss: 107.8123 - val_loss: 103.0489\n",
      "Epoch 36/50\n",
      " - 0s - loss: 107.3674 - val_loss: 99.3815\n",
      "Epoch 37/50\n",
      " - 0s - loss: 104.3325 - val_loss: 98.5748\n",
      "Epoch 38/50\n",
      " - 0s - loss: 111.6296 - val_loss: 97.8222\n",
      "Epoch 39/50\n",
      " - 0s - loss: 105.0493 - val_loss: 98.5564\n",
      "Epoch 40/50\n",
      " - 0s - loss: 102.5666 - val_loss: 97.6715\n",
      "Epoch 41/50\n",
      " - 0s - loss: 99.3669 - val_loss: 99.0195\n",
      "Epoch 42/50\n",
      " - 0s - loss: 101.4984 - val_loss: 94.2096\n",
      "Epoch 43/50\n",
      " - 0s - loss: 99.5884 - val_loss: 93.2691\n",
      "Epoch 44/50\n",
      " - 0s - loss: 96.7434 - val_loss: 92.1213\n",
      "Epoch 45/50\n",
      " - 0s - loss: 97.1112 - val_loss: 93.8542\n",
      "Epoch 46/50\n",
      " - 0s - loss: 98.2591 - val_loss: 95.6299\n",
      "Epoch 47/50\n",
      " - 0s - loss: 94.9564 - val_loss: 103.7300\n",
      "Epoch 48/50\n",
      " - 0s - loss: 98.0510 - val_loss: 101.5320\n",
      "Epoch 49/50\n",
      " - 0s - loss: 94.5519 - val_loss: 93.7413\n",
      "Epoch 50/50\n",
      " - 0s - loss: 92.3266 - val_loss: 90.5427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb2b248e3d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_split=0.3, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24a6bd3b-390d-4d69-97ff-aa6dece650fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102.47720658976648"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "131ec53d-8306-4c16-bc26-b1b0ef242264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MSE_A = []\n",
    "for i in range(50):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=4)\n",
    "    model.fit(X_train, y_train, validation_split=0.3, epochs=50, verbose=0)\n",
    "    predictions = model.predict(X_test)\n",
    "    MSE_A.append(mean_squared_error(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8170f075-1b96-44a4-b3d7-8f4ea5ce8960",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part A: The mean is 75.53692370514727 and the stddev is 6.880653611669151\n"
     ]
    }
   ],
   "source": [
    "print(\"Part A: The mean is {0} and the stddev is {1}\".format(statistics.mean(MSE_A), statistics.stdev(MSE_A)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d6e4722-b17c-4ba2-a903-6a44f80f165b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Part B\n",
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "MSE_B = []\n",
    "for i in range(50):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3, random_state=4)\n",
    "    model.fit(X_train, y_train, validation_split=0.3, epochs=50, verbose=0)\n",
    "    predictions = model.predict(X_test)\n",
    "    MSE_B.append(mean_squared_error(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8a4190e-ba2f-4969-b40f-c977adbcff32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part B: The mean is 73.35910787419775 and the stddev is 43.92787654636143\n"
     ]
    }
   ],
   "source": [
    "print(\"Part B: The mean is {0} and the stddev is {1}\".format(statistics.mean(MSE_B), statistics.stdev(MSE_B)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adb78f16-25d1-4f35-8027-4ea3ae965bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Part C\n",
    "MSE_C = []\n",
    "for i in range(50):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3, random_state=4)\n",
    "    model.fit(X_train, y_train, validation_split=0.3, epochs=100, verbose=0)\n",
    "    predictions = model.predict(X_test)\n",
    "    MSE_C.append(mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e774cf0-ab35-43af-8f00-cac3e1251ecf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part C: The mean is 43.46221746604949 and the stddev is 0.9398197044192829\n"
     ]
    }
   ],
   "source": [
    "print(\"Part C: The mean is {0} and the stddev is {1}\".format(statistics.mean(MSE_C), statistics.stdev(MSE_C)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3590d6c0-3535-410d-a748-cb262e3f89ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Part D\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "MSE_D = []\n",
    "for i in range(50):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3, random_state=4)\n",
    "    model.fit(X_train, y_train, validation_split=0.3, epochs=50, verbose=0)\n",
    "    predictions = model.predict(X_test)\n",
    "    MSE_D.append(mean_squared_error(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f93e320a-9e23-4c08-9aa6-24bb06f24511",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part D: The mean is 48.61115982499302 and the stddev is 25.6255006495377\n"
     ]
    }
   ],
   "source": [
    "print(\"Part D: The mean is {0} and the stddev is {1}\".format(statistics.mean(MSE_D), statistics.stdev(MSE_D)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb890c7-4057-48ed-8d4d-eaa8ec31d68a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
